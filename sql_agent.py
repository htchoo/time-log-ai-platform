from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableSequence
from config import OPENAI_API_KEY
import os
import pandas as pd

# ------------------------------
# ğŸ”¹ í™˜ê²½ ì„¤ì •
# ------------------------------
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

# ê³µìš© LLM ì¸ìŠ¤í„´ìŠ¤ (ë§¤ë²ˆ ì´ˆê¸°í™” ë°©ì§€ â†’ ì„±ëŠ¥ ê°œì„ )
# llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
llm = ChatOpenAI(model="gpt-4o", temperature=0)


# ------------------------------
# ğŸ”¹ SQL ìƒì„± í•¨ìˆ˜
# ------------------------------
def generate_sql(user_query: str) -> str:
    """
    ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆì˜ë¥¼ SQLë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # SQL í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
        with open("prompts/sql_prompt.txt", "r", encoding="utf-8") as f:
            template = f.read()

        prompt = PromptTemplate(
            input_variables=["user_query"],
            template=template + "\n\nUser Query: {user_query}"
        )

        # RunnableSequence êµ¬ì„±
        chain = RunnableSequence(prompt | llm)
        response = chain.invoke({"user_query": user_query})

        # ê²°ê³¼ ì¶”ì¶œ
        sql = response.content if hasattr(response, "content") else str(response)
        return sql.strip("```sql").strip("```").strip()
    except Exception as e:
        return f"-- SQL ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# ------------------------------
# ğŸ”¹ ê²°ê³¼ ìš”ì•½ í•¨ìˆ˜ (ì„ì‹œ ë¹„í™œì„±í™”)
# ------------------------------
# def summarize_result(user_query: str, df: pd.DataFrame) -> str:
#     """
#     SQL ì‹¤í–‰ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ì—¬ ìì—°ì–´ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
#     """
#     try:
#         if df is None or df.empty:
#             return "âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
#
#         # ê²°ê³¼ ìƒ˜í”Œ
#         sample_data = df.head(10).to_string(index=False)
#
#         # ìš”ì•½ìš© í”„ë¡¬í”„íŠ¸
#         summary_prompt = f"""
#         ì‚¬ìš©ìê°€ ë‹¤ìŒ ì§ˆì˜ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤:
#         "{user_query}"
#
#         ê²°ê³¼ ë°ì´í„°ì˜ ì¼ë¶€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
#         {sample_data}
#
#         ìœ„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì£¼ìš” íŒ¨í„´, ì´ìƒì¹˜, ë˜ëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
#         """
#
#         # LLM í˜¸ì¶œ
#         response = llm.invoke(summary_prompt)
#         summary = response.content if hasattr(response, "content") else str(response)
#
#         return summary.strip()
#
#     except Exception as e:
#         return f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# ------------------------------
# ğŸ”¹ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì§ì ‘ ì‹¤í–‰ ì‹œë§Œ ë™ì‘)
# ------------------------------
if __name__ == "__main__":
    test_query = "2025ë…„ë„ ì°¨ìŠ¹ìš°ì˜ íƒ€ì„ë¡œê·¸ ì‘ì„± íŠ¸ë Œë“œë¥¼ ì›”ë‹¨ìœ„ë¡œ ë³´ì—¬ì¤˜"
    sql = generate_sql(test_query)
    print("ğŸ§  ìƒì„±ëœ SQL:\n", sql)

    # ê°€ì§œ ë°ì´í„°í”„ë ˆì„ ì˜ˆì‹œ (í…ŒìŠ¤íŠ¸ìš©)
    dummy_df = pd.DataFrame({
        "year": [2025, 2025, 2025],
        "mm": [1, 2, 3],
        "total_duration": [12.5, 8.3, 15.2]
    })

    # summary = summarize_result(test_query, dummy_df)
    # print("\nğŸ“ ìš”ì•½ ê²°ê³¼:\n", summary)
